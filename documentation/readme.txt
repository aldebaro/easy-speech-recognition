This is an old version.
Recall that ufpaspeech was called Spock.

INSTALLATION

a) You need to set your CLASSPATH to point to 
directory "classes" where you find subdirectories dukov,
edu/ucsd/asr, etc. Another option is creating a jar file
and run
java -jar NAME_OF_FILE_WITH_CLASSES.jar

b) to train HMMs you need to edit the file
welcome.TRN to change the directories there. For
example, instead of /home/aldebaro/..., put the correct
directory you are using.

Obs: dukov.JPR is a Jbuilder project file. Jbuilder
Foundation can be download for free from Borland.

TO USE IT:
1) Record speech files

2) To train HMMs, execute
java dukov.Dukov.
Then open a file training file, for example, welcome.TRN.

3) To test recognition online, execute
java dukov.RunRecognizer hmms.jar
where hmms.jar (or any other name) is the file with HMMs
generated by the step above.

DETAILS

I incorporated the file SpockUsersGuide.htm that has part of the documentation of a bigger speech software called Spock. Maybe that can help to understand Dukov... Anyways it should not be essential.

3 steps for building and testing HMM models for isolated words.
I) Record speech files and organize them in subdirectories below a given root directory.

Do not forget of recording mono (not stereo 2 channels) files.

Choose a root directory. For each word, create a word directory below root. All speech files should be in a word directory or their subdirectories. The speech files can be of type: WAV (Microsoft's Wave), AU (Sun's audio file) or AIFF. So, one can use virtually any sound recorder to record the files, as Window's Sound Recorder or the shareware CoolEdit, for example.

Let's suppose an example with 2 words: yes and no.

Considering the root as C:\Databases, one should create word directory yes:

C:\Databases\yes

and put there files with this word.

Similarly, create word directory no:

C:\Databases\no

The important thing is that below the root, each subdirectory is considered to be a new word. The software will search recursively the subdirectories of word directory (yes and no in this case) to build their two HMM models. So, one could eventually use subdirectories inside a word directory. For example:

C:\Databases\no\speaker1

C:\Databases\no\speaker2

could be used to divide the files of "no" according to the speaker. 

At this point, the software is able to automatically create a file TBL with a table of labels. Each subdirectory of root (word directory) is considered to be a table entry and the subdirectory name is the label associated to such entry. The user himself can build a TBL file too. For this kind of isolated-words application, typically each table entry will have only one label and this label must be the directory name (below the root) associated to that word. The user can create TBL with more than one label per entry, but the first label must be the word directory name. 

II) Create a TRN file with training information (example is welcome.TRN) and run dukov.Dukov

The training procedure basically creates:

a) one SGM segments file;

b) one SOP SetOfPatterns file with the MFCCs;

c) one JAR file with all HMMs compacted in a file that can be opened using Winzip;

and one report file with extension TRN, that can be used as the input file in other simulations.

III) Now, for testing the system.

Run:
java dukov.RunRecognizer hmms.jar

This class is buggy, sorry. I will give you some advices on fixing it:
- the class that doesn't seem to be working is EnergyBasedVoiceActivityDetector.java.
Note the method: public void estimateNoisePower();
It has two empirical thresholds: 30 and 300. You can modify them. The bigger the value, the louder one should speak. For small values, the method is very sensitive to noise and breathing.
m_dlowEnergyThreshold = 30 * environmentModel.getNoiseAveragePower();
m_dhighEnergyThreshold = 300.0 * m_dlowEnergyThreshold;
I suspect the method
private boolean detectSilence(byte[] m_bsoundBytes)
is not working properly. When I say a word, the software repeats it many times.

Good luck !
Aldebaro
